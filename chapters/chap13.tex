\chapter{Machine Learning and Causal Inference for (Reliable) Decision Support.
by \href{https://suchisaria.jhu.edu/}{Suchi Saria}}

 Wed. 16:30--18:00

Algorithmic fairness (eg. suitability of an applicant for a job position)

In a medical environment the label given to a patient after some of the
interventions depend on the actual interventions done to the patient. Eg. if we
have data from a patient before any intervention, and after the interventions
we get a label about their recovery. We can not know if a similar patient is a
right risk, because the label depends on the intervention.

Suchi Saria is proposing the following

\begin{itemize}
  \item The objective is not the prediction $y$ (final label)
  \item Recasting the problem as ``what if'': eg. what would be the outcome of
    the patient if we didn't make any intervention?
\end{itemize}

See Caruana et al., KDD 2015 \cite{caruana2015intelligible}, Schulam and Saria,
NIPS 2017 \cite{schulam2017reliable}

An example of the use of ``what if'' formalization

\begin{itemize}
  \item You are concerned about blood pressure and if you should start to do
    some exercise to improve it.
  \item Formulatoin 1: What if I were to exercise?
  \item Formulation 2: What is the effect of exercise on the blood pressure of
    individuals like myself?
  \item Formulation 3: What is the effect of exercise on blood pressure?
\end{itemize}

Example: Exercise and blood pressure

Core assumptions: Positivity: Every subject has non-zero probability of
receiving every treatment.

Consider the confounders : covariate that has a causal effect on both the
treatment and outcome. Eg. $X \to Z \to Y \leftarrow X$

\begin{figure}[h]
  \centering
  \begin{tikzpicture}
   \node[main node] (z) {$Z$};
    \node[main node] (x) [below left = 1.3cm and 0.5cm of z]  {$X$};
    \node[main node] (y) [below right = 1.3cm and 0.5cm of z] {$Y$};

    \path[->,thick]
    (x) edge node {} (z)
    (x) edge node {} (y)
    (z) edge node {} (y);
  \end{tikzpicture}
  \caption{Causality graph}
\end{figure}

\begin{itemize}
  \item Core assumptions: no unobserved confounders
\end{itemize}

One solution is the randomized control trial that removes one of the causal
relations between a possible confounder $X$ and $Z$. Leaving the causal
connections $X \to Y \leftarrow Z$

\begin{itemize}
  \item Randomize trials may be impossible
  \item In many cases we can collect observational data
  \item \textbf{Assumptions are not always testable from data}
  \item \textbf{No escape}: must rely on domain knowledge
\end{itemize}

\section{Observed confounders}

\subsection{Feature Matching}

\begin{itemize}
  \item Search for all the matches in your data between all the features except
    the one being studied (pairs of treated and untreated individuals who are
    very similar or even identical to each other).
  \item Using any distance metric between sample inputs
\end{itemize}

See Sharma and Kiciman 2018, and Stuart 2010

\subsubsection{Propensity score matching}

In propensity score matching we use a supervised model $e(x)$ that predicts $Z$
given $X$ and creates the new causal graph $X \to e(x) \to Z \to Y \leftarrow
X$. As $e(x)$ is a d-separator, by knowing it we make independent the $X$ from
$Z$.

\begin{figure}[h]
  \centering
  \begin{tikzpicture}
   \node[main node] (z) {$Z$};
   \node[main node] (ex) [below left = 0.5cm and 0.3cm of z]  {$e(X)$};
   \node[main node] (x) [below left = 0.5cm and 0.3cm of ex]  {$X$};
   \node[main node] (y) [right = 2.0cm of x] {$Y$};

    \path[->,thick]
    (x) edge node {} (ex)
    (ex) edge node {} (z)
    (x) edge node {} (y)
    (z) edge node {} (y);
  \end{tikzpicture}
  \caption{Causality graph}
\end{figure}

\begin{enumerate}
  \item Estimate $e(x)$ using supervised learning
    \begin{itemize}
      \item Logistic regression, or other models
      \item The score must be well-calibrated
    \end{itemize}
  \item Distance is the difference between the propensity scores
    \begin{equation}
      Distance(x_i, x_j) = |\hat{e}(x_i) - \hat{e}(x_j)|
    \end{equation}
  \item If the model is perfect and always predicts 1 or 0, it is not possible
    to match the people, as everybody will fall into the same bucket (think
    about assessing calibration when the model only makes predictions 0 or 1)
\end{enumerate}

\subsubsection{Weighting}

\section{References}

\begin{itemize}
  \item See Reliable decision support using conterfactual models \cite{schulam2017reliable}
\end{itemize}

\section{Unstable paths}

Learning $T | C, Y$ is unstable because $C$ still depends on an unknown
variable $D$.

\begin{figure}[h]
  \centering
  \begin{tikzpicture}
   \node[main node] (d) {$D$};
   \node[main node] (t) [below left = 0.6cm and 0.5cm of d]  {$T$};
   \node[main node] (c) [below right = 0.6cm and 0.5cm of d] {$C$};
   \node[main node] (y) [below left = 0.6cm and 0.5cm of c] {$Y$};

   \path[->,thick]
   (d) edge node {} (t)
   (d) edge node {} (c)
   (t) edge node {} (y)
   (c) edge node {} (y);
  \end{tikzpicture}
  \caption{Causality graph}
\end{figure}

Consider naive discriminative model $P(T|C,Y)$, in this case $C$ is
{\color{red}vulnerable} because it has an active unstable path to $T$.

\begin{figure}[h]
  \centering
    \begin{tikzpicture}
     \node[unobserved node] (d) {$D$};
     \node[unobserved node] (t) [below left = 0.6cm and 0.5cm of d]  {$T$};
     \node[observed node] (c) [below right = 0.6cm and 0.5cm of d] {$C$};
     \node[observed node] (y) [below left = 0.6cm and 0.5cm of c] {$Y$};

     \path[->,thick]
     (d) edge node {} (t)
     (t) edge node {} (y)
     (c) edge node {} (y);
     \path[->,thick, color=red]
     (d) edge node {} (c);
  \end{tikzpicture}
  \caption{Vulnerable variables}
\end{figure}

We can create a new feature tha \dots

\begin{figure}[h]
  \centering
    \begin{tikzpicture}
     \node[unobserved node] (d) {$D$};
     \node[unobserved node] (t) [below left = 0.6cm and 0.5cm of d]  {$T$};
     \node[observed node] (c) [below right = 0.6cm and 0.5cm of d] {$C$};
     \node[unobserved node] (yc) [below = 0.6cm of t]  {$Y(C)$};
     \node[observed node] (y) [below right = 0.6cm and 0.5cm of yc] {$Y$};

     \path[->,thick]
     (d) edge node {} (t)
     (t) edge node {} (yc)
     (yc) edge node {} (y)
     (c) edge node {} (y);
     \path[->,thick, color=red]
     (d) edge node {} (c);
  \end{tikzpicture}
  \caption{Vulnerable variables}
\end{figure}
\bibliographystyle{apalike}
\bibliography{references}
